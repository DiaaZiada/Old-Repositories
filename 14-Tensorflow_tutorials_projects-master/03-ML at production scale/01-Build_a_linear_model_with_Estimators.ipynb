{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build_a_linear_model_with_Estimators.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "b5Zbema8jpI8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build a linear model with Estimators\n",
        "This tutorial uses the [tf.estimator](https://www.tensorflow.org/api_docs/python/tf/estimator) API in TensorFlow to solve a benchmark binary classification problem. Estimators are TensorFlow's most scalable and production-oriented model type. For more information see the [Estimator guide](https://www.tensorflow.org/guide/estimators).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sZA0rG34lTOC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "Using census data which contains data a person's age, education, marital status, and occupation (the features), we will try to predict whether or not the person earns more than 50,000 dollars a year (the target label). We will train a logistic regression model that, given an individual's information, outputs a number between 0 and 1—this can be interpreted as the probability that the individual has an annual income of over 50,000 dollars.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Key Point**: As a modeler and developer, think about how this data is used and the potential benefits and harm a model's predictions can cause. A model like this could reinforce societal biases and disparities. Is each feature relevant to the problem you want to solve or will it introduce bias? For more information, read about [ML fairness](https://developers.google.com/machine-learning/fairness-overview/)."
      ]
    },
    {
      "metadata": {
        "id": "aYskbhCBmEd0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "Import TensorFlow, feature column support, and supporting modules:"
      ]
    },
    {
      "metadata": {
        "id": "LLZYcuzpjizo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.feature_column as fc \n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A1IkWf1ZmREk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And let's enable [eager execution](https://www.tensorflow.org/guide/eager) to inspect this program as we run it:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dTw-8acCmPao",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JN8x99k0maHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download the official implementation\n",
        "We'll use the [wide and deep model](https://github.com/tensorflow/models/tree/master/official/wide_deep/) available in TensorFlow's [model repository](https://github.com/tensorflow/models/). Download the code, add the root directory to your Python path, and jump to the `wide_deep` directory:"
      ]
    },
    {
      "metadata": {
        "id": "ZMcVIQ4xmXK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "31e77f9c-403b-4a5e-9b57-a112d33b221f"
      },
      "cell_type": "code",
      "source": [
        "! pip install -q requests\n",
        "! git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2973, done.\u001b[K\n",
            "remote: Counting objects: 100% (2973/2973), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2574/2574), done.\u001b[K\n",
            "remote: Total 2973 (delta 507), reused 1775 (delta 323), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2973/2973), 376.91 MiB | 41.52 MiB/s, done.\n",
            "Resolving deltas: 100% (507/507), done.\n",
            "Checking out files: 100% (2804/2804), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GgoUEjv2myjN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add the root directory of the repository to your Python path:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iOHzO-9SmrHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_path = os.path.join(os.getcwd(), 'models')\n",
        "\n",
        "sys.path.append(models_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJCCae4Am7JL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download the dataset:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qFkwmTHom4Wu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from official.wide_deep import census_dataset\n",
        "from official.wide_deep import census_main\n",
        "\n",
        "census_dataset.download(\"/tmp/census_data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZHr-9TvnD5p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Command line usage**\n",
        "\n",
        "The repo includes a complete program for experimenting with this type of model.\n",
        "\n",
        "To execute the tutorial code from the command line first add the path to tensorflow/models to your `PYTHONPATH`."
      ]
    },
    {
      "metadata": {
        "id": "qluRMf3-m-Pe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export PYTHONPATH=${PYTHONPATH}:\"$(pwd)/models\"\n",
        "#running from python you need to set the `os.environ` or the subprocess will not see the directory.\n",
        "\n",
        "if \"PYTHONPATH\" in os.environ:\n",
        "  os.environ['PYTHONPATH'] += os.pathsep +  models_path\n",
        "else:\n",
        "  os.environ['PYTHONPATH'] = models_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aWD1wVA9nYhJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use `--help` to see what command line options are available:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rYTttDPPnWiZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1078
        },
        "outputId": "e11b27ce-ff86-47cc-e889-2edd20482065"
      },
      "cell_type": "code",
      "source": [
        "!python -m official.wide_deep.census_main --help"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-10-02 18:21:16.713016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-02 18:21:16.713474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-10-02 18:21:16.713543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
            "2018-10-02 18:21:17.080240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-02 18:21:17.080306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
            "2018-10-02 18:21:17.080334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
            "2018-10-02 18:21:17.080621: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-10-02 18:21:17.080695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/device:GPU:0 with 10759 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Train DNN on census income dataset.\n",
            "flags:\n",
            "\n",
            "/content/models/official/wide_deep/census_main.py:\n",
            "  -bs,--batch_size:\n",
            "    Batch size for training and evaluation. When using multiple gpus, this is\n",
            "    the\n",
            "    global batch size for all devices. For example, if the batch size is 32 and\n",
            "    there are 4 GPUs, each GPU will get 8 examples on each step.\n",
            "    (default: '40')\n",
            "    (an integer)\n",
            "  --[no]clean:\n",
            "    If set, model_dir will be removed if it exists.\n",
            "    (default: 'false')\n",
            "  -dd,--data_dir:\n",
            "    The location of the input data.\n",
            "    (default: '/tmp/census_data')\n",
            "  --[no]download_if_missing:\n",
            "    Download data to data_dir if it is not already present.\n",
            "    (default: 'true')\n",
            "  -ebe,--epochs_between_evals:\n",
            "    The number of training epochs to run between evaluations.\n",
            "    (default: '2')\n",
            "    (an integer)\n",
            "  -ed,--export_dir:\n",
            "    If set, a SavedModel serialization of the model will be exported to this\n",
            "    directory at the end of training. See the README for more details and\n",
            "    relevant\n",
            "    links.\n",
            "  -hk,--hooks:\n",
            "    A list of (case insensitive) strings to specify the names of training hooks.\n",
            "    ﻿  Hook:\n",
            "    ﻿    loggingtensorhook\n",
            "    ﻿    profilerhook\n",
            "    ﻿    examplespersecondhook\n",
            "    ﻿    loggingmetrichook\n",
            "    ﻿  Example: `--hooks ProfilerHook,ExamplesPerSecondHook`\n",
            "    See official.utils.logs.hooks_helper for details.\n",
            "    (default: 'LoggingTensorHook')\n",
            "    (a comma separated list)\n",
            "  -md,--model_dir:\n",
            "    The location of the model checkpoint files.\n",
            "    (default: '/tmp/census_model')\n",
            "  -mt,--model_type: <wide|deep|wide_deep>: Select model topology.\n",
            "    (default: 'wide_deep')\n",
            "  -te,--train_epochs:\n",
            "    The number of epochs used to train.\n",
            "    (default: '40')\n",
            "    (an integer)\n",
            "\n",
            "Try --helpfull to get a list of all flags.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ACqS88KenjWK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now run the model:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "w6D5Tr5onfl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2086
        },
        "outputId": "3263eaed-e61c-4b39-d1ad-17ba24a891f6"
      },
      "cell_type": "code",
      "source": [
        "!python -m official.wide_deep.census_main --model_type=wide --train_epochs=2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-10-02 18:21:23.219222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-02 18:21:23.219701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-10-02 18:21:23.219743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
            "2018-10-02 18:21:23.602915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-02 18:21:23.602984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
            "2018-10-02 18:21:23.603011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
            "2018-10-02 18:21:23.603291: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-10-02 18:21:23.603356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/device:GPU:0 with 10759 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "I1002 18:21:23.608392 140338305677184 tf_logging.py:115] Using config: {'_model_dir': '/tmp/census_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
            "  key: \"GPU\"\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa2ab080eb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "W1002 18:21:23.609648 140338305677184 tf_logging.py:120] 'cpuinfo' not imported. CPU info will not be logged.\n",
            "2018-10-02 18:21:23.609814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
            "2018-10-02 18:21:23.609867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-02 18:21:23.609910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
            "2018-10-02 18:21:23.609932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
            "2018-10-02 18:21:23.610184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/device:GPU:0 with 10759 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "I1002 18:21:28.699062 140338305677184 tf_logging.py:115] Benchmark run: {'model_name': 'wide_deep', 'dataset': {'name': 'Census Income'}, 'machine_config': {'gpu_info': {'count': 1, 'model': 'Tesla K80'}, 'memory_total': 13655281664, 'memory_available': 12186841088}, 'test_id': None, 'run_date': '2018-10-02T18:21:23.609144Z', 'tensorflow_version': {'version': '1.11.0', 'git_hash': 'unknown'}, 'tensorflow_environment_variables': [{'name': 'TF_FORCE_GPU_ALLOW_GROWTH', 'value': 'true'}], 'run_parameters': [{'name': 'batch_size', 'long_value': 40}, {'name': 'model_type', 'string_value': 'wide'}, {'name': 'train_epochs', 'long_value': 2}]}\n",
            "I1002 18:21:28.730057 140338305677184 tf_logging.py:115] Parsing /tmp/census_data/adult.data\n",
            "I1002 18:21:28.769205 140338305677184 tf_logging.py:115] Calling model_fn.\n",
            "I1002 18:21:29.959267 140338305677184 tf_logging.py:115] Done calling model_fn.\n",
            "I1002 18:21:29.959625 140338305677184 tf_logging.py:115] Create CheckpointSaverHook.\n",
            "I1002 18:21:30.481102 140338305677184 tf_logging.py:115] Graph was finalized.\n",
            "2018-10-02 18:21:30.481510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-02 18:21:30.481566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      \n",
            "I1002 18:21:30.552793 140338305677184 tf_logging.py:115] Running local_init_op.\n",
            "I1002 18:21:30.564764 140338305677184 tf_logging.py:115] Done running local_init_op.\n",
            "I1002 18:21:31.319625 140338305677184 tf_logging.py:115] Saving checkpoints for 0 into /tmp/census_model/model.ckpt.\n",
            "I1002 18:21:31.858427 140338305677184 tf_logging.py:115] average_loss = 0.6931472, loss = 27.725887\n",
            "I1002 18:21:31.858765 140338305677184 tf_logging.py:115] loss = 27.725887, step = 1\n",
            "I1002 18:21:32.509786 140338305677184 tf_logging.py:115] global_step/sec: 153.442\n",
            "I1002 18:21:32.510622 140338305677184 tf_logging.py:115] average_loss = 0.19567801, loss = 7.8271203 (0.652 sec)\n",
            "I1002 18:21:32.510828 140338305677184 tf_logging.py:115] loss = 7.8271203, step = 101 (0.652 sec)\n",
            "I1002 18:21:32.829666 140338305677184 tf_logging.py:115] global_step/sec: 312.617\n",
            "I1002 18:21:32.830577 140338305677184 tf_logging.py:115] average_loss = 0.37360796, loss = 14.944319 (0.320 sec)\n",
            "I1002 18:21:32.830772 140338305677184 tf_logging.py:115] loss = 14.944319, step = 201 (0.320 sec)\n",
            "I1002 18:21:33.168776 140338305677184 tf_logging.py:115] global_step/sec: 294.875\n",
            "I1002 18:21:33.169598 140338305677184 tf_logging.py:115] average_loss = 0.29609767, loss = 11.843906 (0.339 sec)\n",
            "I1002 18:21:33.169806 140338305677184 tf_logging.py:115] loss = 11.843906, step = 301 (0.339 sec)\n",
            "I1002 18:21:33.490115 140338305677184 tf_logging.py:115] global_step/sec: 311.182\n",
            "I1002 18:21:33.491023 140338305677184 tf_logging.py:115] average_loss = 0.3252378, loss = 13.009512 (0.321 sec)\n",
            "I1002 18:21:33.491239 140338305677184 tf_logging.py:115] loss = 13.009512, step = 401 (0.321 sec)\n",
            "I1002 18:21:33.810629 140338305677184 tf_logging.py:115] global_step/sec: 312.049\n",
            "I1002 18:21:33.811469 140338305677184 tf_logging.py:115] average_loss = 0.47943625, loss = 19.17745 (0.320 sec)\n",
            "I1002 18:21:33.811828 140338305677184 tf_logging.py:115] loss = 19.17745, step = 501 (0.321 sec)\n",
            "I1002 18:21:34.151550 140338305677184 tf_logging.py:115] global_step/sec: 293.313\n",
            "I1002 18:21:34.152523 140338305677184 tf_logging.py:115] average_loss = 0.21928182, loss = 8.771273 (0.341 sec)\n",
            "I1002 18:21:34.152774 140338305677184 tf_logging.py:115] loss = 8.771273, step = 601 (0.341 sec)\n",
            "I1002 18:21:34.482552 140338305677184 tf_logging.py:115] global_step/sec: 302.105\n",
            "I1002 18:21:34.483361 140338305677184 tf_logging.py:115] average_loss = 0.3343677, loss = 13.374707 (0.331 sec)\n",
            "I1002 18:21:34.483596 140338305677184 tf_logging.py:115] loss = 13.374707, step = 701 (0.331 sec)\n",
            "I1002 18:21:34.803413 140338305677184 tf_logging.py:115] global_step/sec: 311.652\n",
            "I1002 18:21:34.804258 140338305677184 tf_logging.py:115] average_loss = 0.28838953, loss = 11.535582 (0.321 sec)\n",
            "I1002 18:21:34.804536 140338305677184 tf_logging.py:115] loss = 11.535582, step = 801 (0.321 sec)\n",
            "I1002 18:21:35.167051 140338305677184 tf_logging.py:115] global_step/sec: 274.985\n",
            "I1002 18:21:35.167878 140338305677184 tf_logging.py:115] average_loss = 0.2612874, loss = 10.451496 (0.364 sec)\n",
            "I1002 18:21:35.168115 140338305677184 tf_logging.py:115] loss = 10.451496, step = 901 (0.364 sec)\n",
            "I1002 18:21:35.499521 140338305677184 tf_logging.py:115] global_step/sec: 300.792\n",
            "I1002 18:21:35.500311 140338305677184 tf_logging.py:115] average_loss = 0.26080233, loss = 10.432093 (0.332 sec)\n",
            "I1002 18:21:35.500572 140338305677184 tf_logging.py:115] loss = 10.432093, step = 1001 (0.332 sec)\n",
            "I1002 18:21:35.817359 140338305677184 tf_logging.py:115] global_step/sec: 314.612\n",
            "I1002 18:21:35.818255 140338305677184 tf_logging.py:115] average_loss = 0.24716249, loss = 9.886499 (0.318 sec)\n",
            "I1002 18:21:35.818471 140338305677184 tf_logging.py:115] loss = 9.886499, step = 1101 (0.318 sec)\n",
            "I1002 18:21:36.136199 140338305677184 tf_logging.py:115] global_step/sec: 313.646\n",
            "I1002 18:21:36.137101 140338305677184 tf_logging.py:115] average_loss = 0.4749628, loss = 18.998512 (0.319 sec)\n",
            "I1002 18:21:36.137328 140338305677184 tf_logging.py:115] loss = 18.998512, step = 1201 (0.319 sec)\n",
            "I1002 18:21:36.455560 140338305677184 tf_logging.py:115] global_step/sec: 313.133\n",
            "I1002 18:21:36.456408 140338305677184 tf_logging.py:115] average_loss = 0.3807271, loss = 15.229084 (0.319 sec)\n",
            "I1002 18:21:36.456771 140338305677184 tf_logging.py:115] loss = 15.229084, step = 1301 (0.319 sec)\n",
            "I1002 18:21:36.794394 140338305677184 tf_logging.py:115] global_step/sec: 295.111\n",
            "I1002 18:21:36.795241 140338305677184 tf_logging.py:115] average_loss = 0.24898124, loss = 9.9592495 (0.339 sec)\n",
            "I1002 18:21:36.795447 140338305677184 tf_logging.py:115] loss = 9.9592495, step = 1401 (0.339 sec)\n",
            "I1002 18:21:37.113668 140338305677184 tf_logging.py:115] global_step/sec: 313.246\n",
            "I1002 18:21:37.114461 140338305677184 tf_logging.py:115] average_loss = 0.2643941, loss = 10.575765 (0.319 sec)\n",
            "I1002 18:21:37.114825 140338305677184 tf_logging.py:115] loss = 10.575765, step = 1501 (0.319 sec)\n",
            "I1002 18:21:37.425391 140338305677184 tf_logging.py:115] global_step/sec: 320.776\n",
            "I1002 18:21:37.426178 140338305677184 tf_logging.py:115] average_loss = 0.37070066, loss = 14.828027 (0.312 sec)\n",
            "I1002 18:21:37.426383 140338305677184 tf_logging.py:115] loss = 14.828027, step = 1601 (0.312 sec)\n",
            "I1002 18:21:37.522951 140338305677184 tf_logging.py:115] Saving checkpoints for 1629 into /tmp/census_model/model.ckpt.\n",
            "I1002 18:21:37.666982 140338305677184 tf_logging.py:115] Loss for final step: 0.91907156.\n",
            "I1002 18:21:37.679466 140338305677184 tf_logging.py:115] Parsing /tmp/census_data/adult.test\n",
            "I1002 18:21:37.716936 140338305677184 tf_logging.py:115] Calling model_fn.\n",
            "W1002 18:21:39.048313 140338305677184 tf_logging.py:125] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "W1002 18:21:39.072806 140338305677184 tf_logging.py:125] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "I1002 18:21:39.097404 140338305677184 tf_logging.py:115] Done calling model_fn.\n",
            "I1002 18:21:39.133771 140338305677184 tf_logging.py:115] Starting evaluation at 2018-10-02-18:21:39\n",
            "I1002 18:21:39.303053 140338305677184 tf_logging.py:115] Graph was finalized.\n",
            "2018-10-02 18:21:39.303427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-02 18:21:39.303499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      \n",
            "I1002 18:21:39.304852 140338305677184 tf_logging.py:115] Restoring parameters from /tmp/census_model/model.ckpt-1629\n",
            "I1002 18:21:39.366219 140338305677184 tf_logging.py:115] Running local_init_op.\n",
            "I1002 18:21:39.398010 140338305677184 tf_logging.py:115] Done running local_init_op.\n",
            "I1002 18:21:41.478350 140338305677184 tf_logging.py:115] Finished evaluation at 2018-10-02-18:21:41\n",
            "I1002 18:21:41.478669 140338305677184 tf_logging.py:115] Saving dict for global step 1629: accuracy = 0.83618945, accuracy_baseline = 0.76377374, auc = 0.8842618, auc_precision_recall = 0.6957708, average_loss = 0.35080227, global_step = 1629, label/mean = 0.23622628, loss = 13.998558, precision = 0.6838167, prediction/mean = 0.2414113, recall = 0.5702028\n",
            "I1002 18:21:41.782467 140338305677184 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 1629: /tmp/census_model/model.ckpt-1629\n",
            "I1002 18:21:41.783203 140338305677184 tf_logging.py:115] Results at epoch 2 / 2\n",
            "I1002 18:21:41.783331 140338305677184 tf_logging.py:115] ------------------------------------------------------------\n",
            "I1002 18:21:41.783453 140338305677184 tf_logging.py:115] accuracy: 0.83618945\n",
            "I1002 18:21:41.783581 140338305677184 tf_logging.py:115] accuracy_baseline: 0.76377374\n",
            "I1002 18:21:41.783699 140338305677184 tf_logging.py:115] auc: 0.8842618\n",
            "I1002 18:21:41.783811 140338305677184 tf_logging.py:115] auc_precision_recall: 0.6957708\n",
            "I1002 18:21:41.783931 140338305677184 tf_logging.py:115] average_loss: 0.35080227\n",
            "I1002 18:21:41.784052 140338305677184 tf_logging.py:115] global_step: 1629\n",
            "I1002 18:21:41.784181 140338305677184 tf_logging.py:115] label/mean: 0.23622628\n",
            "I1002 18:21:41.784293 140338305677184 tf_logging.py:115] loss: 13.998558\n",
            "I1002 18:21:41.784404 140338305677184 tf_logging.py:115] precision: 0.6838167\n",
            "I1002 18:21:41.784532 140338305677184 tf_logging.py:115] prediction/mean: 0.2414113\n",
            "I1002 18:21:41.784657 140338305677184 tf_logging.py:115] recall: 0.5702028\n",
            "I1002 18:21:41.784867 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'accuracy', 'value': 0.8361894488334656, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.784816Z', 'extras': []}\n",
            "I1002 18:21:41.785036 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'accuracy_baseline', 'value': 0.7637737393379211, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.785008Z', 'extras': []}\n",
            "I1002 18:21:41.785195 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'auc', 'value': 0.8842617869377136, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.785166Z', 'extras': []}\n",
            "I1002 18:21:41.785338 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'auc_precision_recall', 'value': 0.695770800113678, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.785309Z', 'extras': []}\n",
            "I1002 18:21:41.785502 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'average_loss', 'value': 0.3508022725582123, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.785450Z', 'extras': []}\n",
            "I1002 18:21:41.785659 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'label/mean', 'value': 0.23622627556324005, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.785618Z', 'extras': []}\n",
            "I1002 18:21:41.785813 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'loss', 'value': 13.998558044433594, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.785783Z', 'extras': []}\n",
            "I1002 18:21:41.785972 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'precision', 'value': 0.68381667137146, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.785943Z', 'extras': []}\n",
            "I1002 18:21:41.786141 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'prediction/mean', 'value': 0.24141129851341248, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.786109Z', 'extras': []}\n",
            "I1002 18:21:41.786301 140338305677184 tf_logging.py:115] Benchmark metric: {'name': 'recall', 'value': 0.5702028274536133, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-02T18:21:41.786272Z', 'extras': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8o-mkNS5nzfG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Read the U.S. Census data\n",
        "This example uses the [U.S Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income) from 1994 and 1995. We have provided the [census_dataset.py](https://github.com/tensorflow/models/tree/master/official/wide_deep/census_dataset.py) script to download the data and perform a little cleanup.\n",
        "\n",
        "Since the task is a binary classification problem, we'll construct a label column named \"label\" whose value is 1 if the income is over 50K, and 0 otherwise. For reference, see the `input_fn` in [census_main.py](https://github.com/tensorflow/models/tree/master/official/wide_deep/census_main.py).\n",
        "\n",
        "Let's look at the data to see which columns we can use to predict the target label:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "w1BQ7ZAnnqYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db69ade9-547a-4608-d23d-eff15a6b4499"
      },
      "cell_type": "code",
      "source": [
        "!ls  /tmp/census_data/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adult.data  adult.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_kIPMc-5oR5V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_file = \"/tmp/census_data/adult.data\"\n",
        "test_file = \"/tmp/census_data/adult.test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kSWaddk3oW-3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[pandas](https://pandas.pydata.org/) provides some convenient utilities for data analysis. Here's a list of columns available in the Census Income dataset:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_AnyTz-NoUW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "72bfddfc-7ae7-42f5-ae78-951427d79cf4"
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "\n",
        "train_df = pandas.read_csv(train_file, header = None, names = census_dataset._CSV_COLUMNS)\n",
        "test_df = pandas.read_csv(test_file, header = None, names = census_dataset._CSV_COLUMNS)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass  fnlwgt  education  education_num  \\\n",
              "0   39         State-gov   77516  Bachelors             13   \n",
              "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
              "2   38           Private  215646    HS-grad              9   \n",
              "3   53           Private  234721       11th              7   \n",
              "4   28           Private  338409  Bachelors             13   \n",
              "\n",
              "       marital_status         occupation   relationship   race  gender  \\\n",
              "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
              "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
              "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
              "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
              "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
              "\n",
              "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
              "0          2174             0              40  United-States          <=50K  \n",
              "1             0             0              13  United-States          <=50K  \n",
              "2             0             0              40  United-States          <=50K  \n",
              "3             0             0              40  United-States          <=50K  \n",
              "4             0             0              40           Cuba          <=50K  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "zZXQPKEFoo0d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The columns are grouped into two types: categorical and continuous columns:\n",
        "\n",
        "* A column is called categorical if its value can only be one of the categories in a finite set. For example, the relationship status of a person (wife, husband, unmarried, etc.) or the education level (high school, college, etc.) are categorical columns.\n",
        "* A column is called continuous if its value can be any numerical value in a continuous range. For example, the capital gain of a person (e.g. $14,084) is a continuous column.\n"
      ]
    },
    {
      "metadata": {
        "id": "CzAPHsNTo50u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Converting Data into Tensors\n",
        "When building a [tf.estimator](https://www.tensorflow.org/api_docs/python/tf/estimator) model, the input data is specified by using an input function (or `input_fn`). This builder function returns a tf[.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) of batches of (`features-dict, label`) pairs. It is not called until it is passed to [tf.estimator.Estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator) methods such as `train` and `evaluate`.\n",
        "\n",
        "The input builder function returns the following pair:\n",
        "\n",
        "1. `features`: A dict from feature names to `Tensors` or `SparseTensors` containing batches of features.\n",
        "2. `labels`: A `Tensor` containing batches of labels.\n",
        "\n",
        "The keys of the `features` are used to configure the model's input layer.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** The input function is called while constructing the TensorFlow graph, not while running the graph. It is returning a representation of the input data as a sequence of TensorFlow graph operations.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "For small problems like this, it's easy to make a [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) by slicing the `pandas.DataFrame`:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "T7EBSK9rohqm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def easy_input_function(df, label_key, num_epochs, shuffle, batch_size):\n",
        "  label = df[label_key]\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df),label))\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XFoG6vmzqYGz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we have eager execution enabled, it's easy to inspect the resulting dataset:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JWonkS-PqWo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ff8ed9a9-4432-4fb7-922a-22e077e3eb81"
      },
      "cell_type": "code",
      "source": [
        "ds = easy_input_function(train_df, label_key='income_bracket', num_epochs=5, shuffle=True, batch_size=10)\n",
        "\n",
        "for feature_batch, label_batch in ds.take(1):\n",
        "  print('Some feature keys:', list(feature_batch.keys())[:5])\n",
        "  print()\n",
        "  print('A batch of Ages  :', feature_batch['age'])\n",
        "  print()\n",
        "  print('A batch of Labels:', label_batch )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
            "\n",
            "A batch of Ages  : tf.Tensor([49 58 53 28 26 35 48 36 63 39], shape=(10,), dtype=int32)\n",
            "\n",
            "A batch of Labels: tf.Tensor(\n",
            "[b'<=50K' b'>50K' b'<=50K' b'<=50K' b'<=50K' b'<=50K' b'<=50K' b'<=50K'\n",
            " b'<=50K' b'>50K'], shape=(10,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YxwtfPkJqtzL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But this approach has severly-limited scalability. Larger datasets should be streamed from disk. The `census_dataset.input_fn` provides an example of how to do this using [tf.decode_csv](https://www.tensorflow.org/api_docs/python/tf/decode_csv) and [tf.data.TextLineDataset](https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset):"
      ]
    },
    {
      "metadata": {
        "id": "dZcj-m-GqcJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "1995c56c-bcd9-42f5-e2df-e4c3ee313048"
      },
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.getsource(census_dataset.input_fn))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
            "  \"\"\"Generate an input function for the Estimator.\"\"\"\n",
            "  assert tf.gfile.Exists(data_file), (\n",
            "      '%s not found. Please make sure you have run census_dataset.py and '\n",
            "      'set the --data_dir argument to the correct path.' % data_file)\n",
            "\n",
            "  def parse_csv(value):\n",
            "    tf.logging.info('Parsing {}'.format(data_file))\n",
            "    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
            "    features = dict(zip(_CSV_COLUMNS, columns))\n",
            "    labels = features.pop('income_bracket')\n",
            "    classes = tf.equal(labels, '>50K')  # binary classification\n",
            "    return features, classes\n",
            "\n",
            "  # Extract lines from input files using the Dataset API.\n",
            "  dataset = tf.data.TextLineDataset(data_file)\n",
            "\n",
            "  if shuffle:\n",
            "    dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\n",
            "\n",
            "  dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
            "\n",
            "  # We call repeat after shuffling, rather than before, to prevent separate\n",
            "  # epochs from blending together.\n",
            "  dataset = dataset.repeat(num_epochs)\n",
            "  dataset = dataset.batch(batch_size)\n",
            "  return dataset\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WLOyiZIHrYJf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This `input_fn` returns equivalent output:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ozUr3KwzrHQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "28353cd9-0e01-4b7d-e842-c29deeae413b"
      },
      "cell_type": "code",
      "source": [
        "ds = census_dataset.input_fn(train_file, num_epochs=5, shuffle=True, batch_size=10)\n",
        "\n",
        "for feature_batch, label_batch in ds.take(1):\n",
        "  print('Feature keys:', list(feature_batch.keys())[:5])\n",
        "  print()\n",
        "  print('Age batch   :', feature_batch['age'])\n",
        "  print()\n",
        "  print('Label batch :', label_batch )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Parsing /tmp/census_data/adult.data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "I1002 18:22:00.266650 140052242024320 tf_logging.py:115] Parsing /tmp/census_data/adult.data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
            "\n",
            "Age batch   : tf.Tensor([27 44 53 25 50 42 47 17 47 54], shape=(10,), dtype=int32)\n",
            "\n",
            "Label batch : tf.Tensor([False False  True  True False  True  True False  True False], shape=(10,), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ebjg9TP9rjm9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because `Estimators` expect an `input_fn` that takes no arguments, we typically wrap configurable input function into an obejct with the expected signature. For this notebook configure the `train_inpf` to iterate over the data twice:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Pq85e-gnrbSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "train_inpf = functools.partial(census_dataset.input_fn, train_file, num_epochs=2, shuffle=True, batch_size=64)\n",
        "test_inpf = functools.partial(census_dataset.input_fn, test_file, num_epochs=1, shuffle=False, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qd1yIt2yvKlU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Selecting and Engineering Features for the Model\n",
        "Estimators use a system called [feature columns](https://www.tensorflow.org/guide/feature_columns) to describe how the model should interpret each of the raw input features. An Estimator expects a vector of numeric inputs, and feature columns describe how the model should convert each feature.\n",
        "\n",
        "Selecting and crafting the right set of feature columns is key to learning an effective model. A feature column can be either one of the raw inputs in the original features `dict` (a base feature column), or any new columns created using transformations defined over one or multiple base columns (a derived feature columns).\n",
        "\n",
        "A feature column is an abstract concept of any raw or derived variable that can be used to predict the target label.\n",
        "\n",
        "## Base Feature Columns\n",
        "### Numeric columns\n",
        "The simplest `feature_column` is `numeric_column`. This indicates that a feature is a numeric value that should be input to the model directly. For example:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Y9mYbLeDrvqF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "age = fc.numeric_column('age')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvPx8ctBv9EH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model will use the `feature_column` definitions to build the model input. You can inspect the resulting output using the `input_layer` function:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "i5pGeQccv6yZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "ec5e04a6-74a4-41e4-e461-fa2cea91cb53"
      },
      "cell_type": "code",
      "source": [
        "fc.input_layer(feature_batch, [age]).numpy()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.],\n",
              "       [44.],\n",
              "       [53.],\n",
              "       [25.],\n",
              "       [50.],\n",
              "       [42.],\n",
              "       [47.],\n",
              "       [17.],\n",
              "       [47.],\n",
              "       [54.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "6FcB088QwKhM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following will train and evaluate a model using only the `age` feature:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YAGKanUXwG-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "05443e3c-0edc-4c77-ac1f-861b7d72c0db"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(feature_columns=[age])\n",
        "classifier.train(train_inpf)\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()  # used for display in notebook\n",
        "print(result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.76352805, 'accuracy_baseline': 0.76377374, 'auc': 0.6781596, 'auc_precision_recall': 0.311341, 'average_loss': 0.5254081, 'label/mean': 0.23622628, 'loss': 33.54576, 'precision': 0.35714287, 'prediction/mean': 0.21536572, 'recall': 0.001300052, 'global_step': 1018}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q6BXbIcNwadY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Similarly, we can define a `NumericColumn` for each continuous feature column that we want to use in the model:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dJiYKlA9wVce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0d1a3ff8-a3dd-410c-9a48-e84d74417de2"
      },
      "cell_type": "code",
      "source": [
        "education_num = tf.feature_column.numeric_column('education_num')\n",
        "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
        "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
        "hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
        "\n",
        "my_numeric_columns = [age,education_num, capital_gain, capital_loss, hours_per_week]\n",
        "\n",
        "fc.input_layer(feature_batch, my_numeric_columns).numpy()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.700e+01, 0.000e+00, 0.000e+00, 1.300e+01, 4.000e+01],\n",
              "       [4.400e+01, 0.000e+00, 0.000e+00, 1.000e+01, 6.000e+01],\n",
              "       [5.300e+01, 0.000e+00, 0.000e+00, 1.100e+01, 4.000e+01],\n",
              "       [2.500e+01, 5.178e+03, 0.000e+00, 7.000e+00, 4.000e+01],\n",
              "       [5.000e+01, 0.000e+00, 0.000e+00, 1.000e+01, 4.000e+01],\n",
              "       [4.200e+01, 9.562e+03, 0.000e+00, 1.300e+01, 4.500e+01],\n",
              "       [4.700e+01, 0.000e+00, 0.000e+00, 1.000e+01, 5.000e+01],\n",
              "       [1.700e+01, 0.000e+00, 0.000e+00, 7.000e+00, 5.000e+00],\n",
              "       [4.700e+01, 7.688e+03, 0.000e+00, 1.400e+01, 4.500e+01],\n",
              "       [5.400e+01, 0.000e+00, 0.000e+00, 9.000e+00, 4.000e+01]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "HhncHdDzwv8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You could retrain a model on these features by changing the `feature_columns` argument to the constructor:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "U4xd76tBwmKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "792e9660-b977-4d11-bbda-f6a21bb7960e"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns)\n",
        "classifier.train(train_inpf)\n",
        "\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "for key,value in sorted(result.items()):\n",
        "  print('%s: %s' % (key, value))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.787728\n",
            "accuracy_baseline: 0.76377374\n",
            "auc: 0.70704854\n",
            "auc_precision_recall: 0.5409346\n",
            "average_loss: 0.5204191\n",
            "global_step: 1018\n",
            "label/mean: 0.23622628\n",
            "loss: 33.22723\n",
            "precision: 0.6575121\n",
            "prediction/mean: 0.23421305\n",
            "recall: 0.21164846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PvJeEmYQw9jZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Categorical columns\n",
        "To define a feature column for a categorical feature, create a `CategoricalColumn` using one of the `tf.feature_column.categorical_column*` functions.\n",
        "\n",
        "If you know the set of all possible feature values of a column—and there are only a few of them—use `categorical_column_with_vocabulary_list`. Each key in the list is assigned an auto-incremented ID starting from 0. For example, for the `relationship` column we can assign the feature string `Husband` to an integer ID of 0 and \"Not-in-family\" to 1, etc."
      ]
    },
    {
      "metadata": {
        "id": "ks32Pnq0w3gX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "relationship = fc.categorical_column_with_vocabulary_list(\n",
        "    'relationship',\n",
        "    ['Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HA9HXvkxiiI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This creates a sparse one-hot vector from the raw input feature.\n",
        "\n",
        "The `input_layer` function we're using is designed for DNN models and expects dense inputs. To demonstrate the categorical column we must wrap it in a [tf.feature_column.indicator_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column) to create the dense one-hot output (Linear `Estimators` can often skip this dense-step).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Note: the other sparse-to-dense option is [tf.feature_column.embedding_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Run the input layer, configured with both the `age` and `relationship` columns:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "X1Dx4nvCxVUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a34d5495-2c53-4b18-da6d-51f285104cb7"
      },
      "cell_type": "code",
      "source": [
        "fc.input_layer(feature_batch, [age, fc.indicator_column(relationship)])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=4563, shape=(10, 7), dtype=float32, numpy=\n",
              "array([[27.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
              "       [44.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
              "       [53.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [25.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [50.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
              "       [42.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
              "       [47.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [17.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
              "       [47.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [54.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "Ch25-shUx4y1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "If we don't know the set of possible values in advance, use the `categorical_column_with_hash_bucket` instead:"
      ]
    },
    {
      "metadata": {
        "id": "jsnMm2Qkx_Pg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "    'occupation', hash_bucket_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8uth49IWyCQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, each possible value in the feature column `occupation` is hashed to an integer ID as we encounter them in training. The example batch has a few different occupations:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ylrCCi0Dxz5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "fb3e2df2-5d01-48f4-c078-b2c89bcacb31"
      },
      "cell_type": "code",
      "source": [
        "for item in feature_batch['occupation'].numpy():\n",
        "    print(item.decode())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exec-managerial\n",
            "Machine-op-inspct\n",
            "Tech-support\n",
            "Transport-moving\n",
            "Other-service\n",
            "Adm-clerical\n",
            "Sales\n",
            "Other-service\n",
            "Prof-specialty\n",
            "Transport-moving\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FcdZ35JXyMBO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we run `input_layer` with the hashed column, we see that the output shape is (`batch_size, hash_bucket_size`):\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zBW_NajtyGjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bec901de-4217-4a05-e955-b637d609f976"
      },
      "cell_type": "code",
      "source": [
        "occupation_result = fc.input_layer(feature_batch, [fc.indicator_column(occupation)])\n",
        "\n",
        "occupation_result.numpy().shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "yzVja7bayVoy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's easier to see the actual results if we take the [tf.argmax](https://www.tensorflow.org/api_docs/python/tf/argmax) over the `hash_bucket_size` dimension. Notice how any duplicate occupations are mapped to the same pseudo-random index:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "as_ZE9Q1ySr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e631730-6335-4f0a-93a6-9b35733b3fbe"
      },
      "cell_type": "code",
      "source": [
        "tf.argmax(occupation_result, axis=1).numpy()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([800, 911, 413, 420, 527,  96, 631, 527, 979, 420])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "dS0-XGgWytPx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Note: Hash collisions are unavoidable, but often have minimal impact on model quiality. The effect may be noticable if the hash buckets are being used to compress the input space. See [this notebook](https://colab.research.google.com/github/tensorflow/models/blob/master/samples/outreach/blogs/housing_prices.ipynb) for a more visual example of the effect of these hash collisions.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "No matter how we choose to define a `SparseColumn`, each feature string is mapped into an integer ID by looking up a fixed mapping or by hashing. Under the hood, the `LinearModel` class is responsible for managing the mapping and creating [tf.Variable](https://www.tensorflow.org/api_docs/python/tf/Variable) to store the model parameters (model weights) for each feature ID. The model parameters are learned through the model training process described later.\n",
        "\n",
        "Let's do the similar trick to define the other categorical features:"
      ]
    },
    {
      "metadata": {
        "id": "fFqL0IM9ylR1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'education', [\n",
        "        'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
        "        'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
        "        '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\n",
        "\n",
        "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'marital_status', [\n",
        "        'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\n",
        "        'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\n",
        "\n",
        "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'workclass', [\n",
        "        'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\n",
        "        'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\n",
        "\n",
        "\n",
        "my_categorical_columns = [relationship, occupation, education, marital_status, workclass]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pw4SNUAc0E7x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's easy to use both sets of columns to configure a model that uses all these features:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9pO2yMXJ0DJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "87768b58-0eda-45d8-f15f-5402ed9b5ba0"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns+my_categorical_columns)\n",
        "classifier.train(train_inpf)\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "for key,value in sorted(result.items()):\n",
        "  print('%s: %s' % (key, value))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.79356307\n",
            "accuracy_baseline: 0.76377374\n",
            "auc: 0.8665625\n",
            "auc_precision_recall: 0.635723\n",
            "average_loss: 1.5507218\n",
            "global_step: 1018\n",
            "label/mean: 0.23622628\n",
            "loss: 99.009026\n",
            "precision: 0.54193324\n",
            "prediction/mean: 0.36764777\n",
            "recall: 0.8148726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M7FFOQAl08UQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Derived feature columns\n",
        "### Make Continuous Features Categorical through Bucketization\n",
        "Sometimes the relationship between a continuous feature and the label is not linear. For example, age and income—a person's income may grow in the early stage of their career, then the growth may slow at some point, and finally, the income decreases after retirement. In this scenario, using the raw `age` as a real-valued feature column might not be a good choice because the model can only learn one of the three cases:\n",
        "\n",
        "1. Income always increases at some rate as age grows (positive correlation),\n",
        "2. Income always decreases at some rate as age grows (negative correlation), or\n",
        "3. Income stays the same no matter at what age (no correlation).\n",
        "\n",
        "If we want to learn the fine-grained correlation between income and each age group separately, we can leverage bucketization. Bucketization is a process of dividing the entire range of a continuous feature into a set of consecutive buckets, and then converting the original numerical feature into a bucket ID (as a categorical feature) depending on which bucket that value falls into. So, we can define a `bucketized_column` over `age` as:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RJaILJJp0woC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "age_buckets = tf.feature_column.bucketized_column(\n",
        "    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yId0NIGf8PgU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`boundaries` is a list of bucket boundaries. In this case, there are 10 boundaries, resulting in 11 age group buckets (from age 17 and below, 18-24, 25-29, ..., to 65 and over).\n",
        "\n",
        "With bucketing, the model sees each bucket a one-hot feature:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cBn1XYHm8Mw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d6f5bc32-315e-40ec-8f98-044ee0d970c1"
      },
      "cell_type": "code",
      "source": [
        "fc.input_layer(feature_batch, [age, age_buckets]).numpy()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [44.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [53.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
              "       [25.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [50.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
              "       [42.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [47.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
              "       [17.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [47.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
              "       [54.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "JGXTg0pz8tSy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Learn complex relationships with crossed column\n",
        "Using each base feature column separately may not be enough to explain the data. For example, the correlation between education and the label (earning > 50,000 dollars) may be different for different occupations. Therefore, if we only learn a single model weight for `education=\"Bachelors\"` and `education=\"Masters\",` we won't capture every education-occupation combination (e.g. distinguishing between `education=\"Bachelors\"` AND `occupation=\"Exec-managerial\"` AND `education=\"Bachelors\" AND occupation=\"Craft-repair\").`\n",
        "\n",
        "To learn the differences between different feature combinations, we can add crossed feature columns to the model:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "LjkmbUWT8ZLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "education_x_occupation = tf.feature_column.crossed_column(\n",
        "    ['education', 'occupation'], hash_bucket_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2eTCoREz9CHh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also create a `crossed_column` over more than two columns. Each constituent column can be either a base feature column that is categorical (`SparseColumn`), a bucketized real-valued feature column, or even another CrossColumn. For example:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mfDtKfrF8_CI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "age_buckets_x_education_x_occupation = tf.feature_column.crossed_column(\n",
        "    [age_buckets, 'education', 'occupation'], hash_bucket_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5q8QpehG9KXY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These crossed columns always use hash buckets to avoid the exponential explosion in the number of categories, and put the control over number of model weights in the hands of the user.\n",
        "\n",
        "For a visual example the effect of hash-buckets with crossed columns see [this notebook](https://colab.research.google.com/github/tensorflow/models/blob/master/samples/outreach/blogs/housing_prices.ipynb)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "k_QPM68S9Wbs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define the logistic regression model\n",
        "After processing the input data and defining all the feature columns, we can put them together and build a logistic regression model. The previous section showed several types of base and derived feature columns, including:\n",
        "\n",
        "* `CategoricalColumn`\n",
        "* `NumericColumn`\n",
        "* `BucketizedColumn`\n",
        "* `CrossedColumn`\n",
        "\n",
        "All of these are subclasses of the abstract `FeatureColumn` class and can be added to the `feature_columns` field of a model:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PpMMAM_29GWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "ef30f945-cf03-4bdc-aa41-9d24df451b0d"
      },
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "base_columns = [\n",
        "    education, marital_status, relationship, workclass, occupation,\n",
        "    age_buckets,\n",
        "]\n",
        "\n",
        "crossed_columns = [\n",
        "    tf.feature_column.crossed_column(\n",
        "        ['education', 'occupation'], hash_bucket_size=1000),\n",
        "    tf.feature_column.crossed_column(\n",
        "        [age_buckets, 'education', 'occupation'], hash_bucket_size=1000),\n",
        "]\n",
        "\n",
        "model = tf.estimator.LinearClassifier(\n",
        "    model_dir=tempfile.mkdtemp(), \n",
        "    feature_columns=base_columns + crossed_columns,\n",
        "    optimizer=tf.train.FtrlOptimizer(learning_rate=0.1))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1002 18:23:35.661538 140052242024320 tf_logging.py:115] Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpf5_328gj', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ff74e5be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1002 18:23:35.664922 140052242024320 tf_logging.py:115] Using config: {'_model_dir': '/tmp/tmpf5_328gj', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ff74e5be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "u5f8zITK9xow",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model automatically learns a bias term, which controls the prediction made without observing any features. The learned model files are stored in `model_dir`."
      ]
    },
    {
      "metadata": {
        "id": "h4zgytBj92i_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train and evaluate the model\n",
        "After adding all the features to the model, let's train the model. Training a model is just a single command using the [tf.estimator](https://www.tensorflow.org/api_docs/python/tf/estimator) API:"
      ]
    },
    {
      "metadata": {
        "id": "iMZ3O-Ia9sxe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_inpf = functools.partial(census_dataset.input_fn, train_file, \n",
        "                               num_epochs=40, shuffle=True, batch_size=64)\n",
        "\n",
        "model.train(train_inpf)\n",
        "\n",
        "clear_output()  # used for notebook display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8LQf8gnf-v6W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After the model is trained, evaluate the accuracy of the model by predicting the labels of the holdout data:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CujIXwDF-tiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7d4061dd-6306-4783-bc14-625c4188df2f"
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "for key,value in sorted(result.items()):\n",
        "  print('%s: %0.2f' % (key, value))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.79\n",
            "accuracy_baseline: 0.76\n",
            "auc: 0.87\n",
            "auc_precision_recall: 0.64\n",
            "average_loss: 1.55\n",
            "global_step: 1018.00\n",
            "label/mean: 0.24\n",
            "loss: 99.01\n",
            "precision: 0.54\n",
            "prediction/mean: 0.37\n",
            "recall: 0.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4DsWME5e-_IM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first line of the output should display something like: `accuracy: 0.83`, which means the accuracy is 83%. You can try using more features and transformations to see if you can do better!\n",
        "\n",
        "After the model is evaluated, we can use it to predict whether an individual has an annual income of over 50,000 dollars given an individual's information input.\n",
        "\n",
        "Let's look in more detail how the model performed:"
      ]
    },
    {
      "metadata": {
        "id": "jOAddflI-43Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "b25c4e11-fe1b-4720-f7f4-3fc01db36074"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "predict_df = test_df[:20].copy()\n",
        "\n",
        "pred_iter = model.predict(\n",
        "    lambda:easy_input_function(predict_df, label_key='income_bracket',\n",
        "                               num_epochs=1, shuffle=False, batch_size=10))\n",
        "\n",
        "classes = np.array(['<=50K', '>50K'])\n",
        "pred_class_id = []\n",
        "\n",
        "for pred_dict in pred_iter:\n",
        "  pred_class_id.append(pred_dict['class_ids'])\n",
        "\n",
        "predict_df['predicted_class'] = classes[np.array(pred_class_id)]\n",
        "predict_df['correct'] = predict_df['predicted_class'] == predict_df['income_bracket']\n",
        "\n",
        "clear_output()\n",
        "\n",
        "predict_df[['income_bracket','predicted_class', 'correct']]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income_bracket</th>\n",
              "      <th>predicted_class</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   income_bracket predicted_class  correct\n",
              "0           <=50K           <=50K     True\n",
              "1           <=50K           <=50K     True\n",
              "2            >50K           <=50K    False\n",
              "3            >50K           <=50K    False\n",
              "4           <=50K           <=50K     True\n",
              "5           <=50K           <=50K     True\n",
              "6           <=50K           <=50K     True\n",
              "7            >50K            >50K     True\n",
              "8           <=50K           <=50K     True\n",
              "9           <=50K           <=50K     True\n",
              "10           >50K           <=50K    False\n",
              "11          <=50K            >50K    False\n",
              "12          <=50K           <=50K     True\n",
              "13          <=50K           <=50K     True\n",
              "14           >50K           <=50K    False\n",
              "15           >50K            >50K     True\n",
              "16          <=50K           <=50K     True\n",
              "17          <=50K           <=50K     True\n",
              "18          <=50K           <=50K     True\n",
              "19           >50K            >50K     True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "XEYnXhJa_aWK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For a working end-to-end example, download our [example code](https://github.com/tensorflow/models/tree/master/official/wide_deep/census_main.py[link text](https://) and set the `model_type` flag to `wide`.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0YHcct_N_t2e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Adding Regularization to Prevent Overfitting\n",
        "Regularization is a technique used to avoid overfitting. Overfitting happens when a model performs well on the data it is trained on, but worse on test data that the model has not seen before. Overfitting can occur when a model is excessively complex, such as having too many parameters relative to the number of observed training data. Regularization allows you to control the model's complexity and make the model more generalizable to unseen data.\n",
        "\n",
        "You can add L1 and L2 regularizations to the model with the following code"
      ]
    },
    {
      "metadata": {
        "id": "6LLkhdV9_VF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "73e45f06-9137-4167-91ba-f29dc6eb6d99"
      },
      "cell_type": "code",
      "source": [
        "model_l1 = tf.estimator.LinearClassifier(\n",
        "    feature_columns=base_columns + crossed_columns,\n",
        "    optimizer=tf.train.FtrlOptimizer(\n",
        "        learning_rate=0.1,\n",
        "        l1_regularization_strength=10.0,\n",
        "        l2_regularization_strength=0.0))\n",
        "\n",
        "model_l1.train(train_inpf)\n",
        "\n",
        "results = model_l1.evaluate(test_inpf)\n",
        "clear_output()\n",
        "for key in sorted(results):\n",
        "  print('%s: %0.2f' % (key, results[key]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.84\n",
            "accuracy_baseline: 0.76\n",
            "auc: 0.88\n",
            "auc_precision_recall: 0.69\n",
            "average_loss: 0.35\n",
            "global_step: 20351.00\n",
            "label/mean: 0.24\n",
            "loss: 22.47\n",
            "precision: 0.69\n",
            "prediction/mean: 0.24\n",
            "recall: 0.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ztmm42_R_8j4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "24cf94e4-c126-46c8-b9a5-70c452f7c2db"
      },
      "cell_type": "code",
      "source": [
        "model_l2 = tf.estimator.LinearClassifier(\n",
        "    feature_columns=base_columns + crossed_columns,\n",
        "    optimizer=tf.train.FtrlOptimizer(\n",
        "        learning_rate=0.1,\n",
        "        l1_regularization_strength=0.0,\n",
        "        l2_regularization_strength=10.0))\n",
        "\n",
        "model_l2.train(train_inpf)\n",
        "\n",
        "results = model_l2.evaluate(test_inpf)\n",
        "clear_output()\n",
        "for key in sorted(results):\n",
        "  print('%s: %0.2f' % (key, results[key]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.84\n",
            "accuracy_baseline: 0.76\n",
            "auc: 0.88\n",
            "auc_precision_recall: 0.69\n",
            "average_loss: 0.35\n",
            "global_step: 20351.00\n",
            "label/mean: 0.24\n",
            "loss: 22.46\n",
            "precision: 0.69\n",
            "prediction/mean: 0.24\n",
            "recall: 0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q0URUOfaAE0S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These regularized models don't perform much better than the base model. Let's look at the model's weight distributions to better see the effect of the regularization:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qhjre40fAAWN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_flat_weights(model):\n",
        "  weight_names = [\n",
        "      name for name in model.get_variable_names()\n",
        "      if \"linear_model\" in name and \"Ftrl\" not in name]\n",
        "\n",
        "  weight_values = [model.get_variable_value(name) for name in weight_names]\n",
        "\n",
        "  weights_flat = np.concatenate([item.flatten() for item in weight_values], axis=0)\n",
        "\n",
        "  return weights_flat\n",
        "\n",
        "weights_flat = get_flat_weights(model)\n",
        "weights_flat_l1 = get_flat_weights(model_l1)\n",
        "weights_flat_l2 = get_flat_weights(model_l2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahe9n1iYALAB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The models have many zero-valued weights caused by unused hash bins (there are many more hash bins than categories in some columns). We can mask these weights when viewing the weight distributions:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UHyLHziPAIpj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight_mask = weights_flat != 0\n",
        "\n",
        "weights_base = weights_flat[weight_mask]\n",
        "weights_l1 = weights_flat_l1[weight_mask]\n",
        "weights_l2 = weights_flat_l2[weight_mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rCAa5pWARyE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now plot the distributions:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YGYDWSFuAQB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1051
        },
        "outputId": "65fa64fa-efcd-4fbf-e65a-0c05d81c55a7"
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "_ = plt.hist(weights_base, bins=np.linspace(-3,3,30))\n",
        "plt.title('Base Model')\n",
        "plt.ylim([0,500])\n",
        "\n",
        "plt.figure()\n",
        "_ = plt.hist(weights_l1, bins=np.linspace(-3,3,30))\n",
        "plt.title('L1 - Regularization')\n",
        "plt.ylim([0,500])\n",
        "\n",
        "plt.figure()\n",
        "_ = plt.hist(weights_l2, bins=np.linspace(-3,3,30))\n",
        "plt.title('L2 - Regularization')\n",
        "_=plt.ylim([0,500])\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFZCAYAAABJ+lxSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5fe77a6898>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFZCAYAAABJ+lxSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5fe761c588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFZCAYAAABJ+lxSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBiDIAAAY4P8AYn4nE0JnySkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5fe768c9b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Q13KmJrNAXtL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Both types of regularization squeeze the distribution of weights towards zero. L2 regularization has a greater effect in the tails of the distribution eliminating extreme weights. L1 regularization produces more exactly-zero values, in this case it sets ~200 to zero.\n",
        "\n"
      ]
    }
  ]
}