{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_generation_with_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oM1bRxHTg_6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cd998d01-7f8b-43bd-cf03-e3e2e8ba8476"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "0MCf3yXsiuOx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparing the data"
      ]
    },
    {
      "metadata": {
        "id": "o65patgphJGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5727469d-0a7a-4e54-be59-f1a7b95b3e8c"
      },
      "cell_type": "code",
      "source": [
        "path = keras.utils.get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QOVjFxuDhzAu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2c771e80-96cf-410b-d91f-8933bf861d1f"
      },
      "cell_type": "code",
      "source": [
        "# Length of extracted character sequences\n",
        "maxlen = 60\n",
        "\n",
        "# We sample a new sequence every `step` characters\n",
        "step = 3\n",
        "\n",
        "# This holds our extracted sequences\n",
        "sentences = []\n",
        "\n",
        "# This holds the targets (the follow-up characters)\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Number of sequences:', len(sentences))\n",
        "\n",
        "# List of unique characters in the corpus\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique characters:', len(chars))\n",
        "# Dictionary mapping unique characters to their index in `chars`\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "# Next, one-hot encode the characters into binary arrays.\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200278\n",
            "Unique characters: 57\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OWZ_iCPniqp0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building the network"
      ]
    },
    {
      "metadata": {
        "id": "JYOpeEroinRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras import layers\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.CuDNNLSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lt-lcN2Fi6s6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "imdhv0YhjB8m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training the language model and sampling from it"
      ]
    },
    {
      "metadata": {
        "id": "OO6rzQxamQ4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vpvT7zgJjAC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1364
        },
        "outputId": "1a561c6f-ef08-4ddd-fd72-6c51f40cf906"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "for epoch in range(1, 60):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(x, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated_text = text[start_index: start_index + maxlen]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "Epoch 1/1\n",
            "200278/200278 [==============================] - 39s 193us/step - loss: 1.9689\n",
            "--- Generating with seed: \"e. and so also in politicis.\n",
            "a statesman who rears up for th\"\n",
            "------ temperature: 0.2\n",
            "e. and so also in politicis.\n",
            "a statesman who rears up for the most and the most man and the man and the realing the man of the precestion of the man of the man of the man and the man one will and the man of the precession of the man and the more something the most in the more the entire of the soul of the self-something the most and something of the man of the something the most man and the most concertion of the most the precession. the more something the\n",
            "------ temperature: 0.5\n",
            "oncertion of the most the precession. the more something the posil all a love and the beals without whom some are the deserved to the the same and the conscition of the enlogeral in fallers of the even discoperation, the religious to poun as only to a the reades the disitality of and the chally and self-pare of everything of the estible of the agreadned and the mote barity of the ears a desponity of the hame of the less and the most a precession and destra\n",
            "------ temperature: 1.0\n",
            "of the hame of the less and the most a precession and destray factible thempther, what is the fellince in\n",
            "such and the parsene. the\n",
            "rebesions? and human dimen;tal are--develo, hamself--which\n",
            "which is as the rageing is the\n",
            "in e. activest agnore, something; happinable of so sex beampise gate, the meanogoves. acciptial,\" and in \"purion. the hredve aarbly lost to comever lell came in light ove quare of suctress. exprebot that even in-pertooin of him medies, a(\n",
            "------ temperature: 1.2\n",
            "f suctress. exprebot that even in-pertooin of him medies, a(lacble for and lootbon., grome (posility's. of the a mea will presple compeife propegales.=--now a\n",
            "wental past vereoter it is, de\"s, periongly atwaysely and in the\n",
            "ene'singlom,, for\n",
            "suedemoum, (araoziogy, in other's.\n",
            "lis ob- chomous even ons\n",
            "? is \"be cappinces--theis fiest and kmore wlyem nompition thriker-parg a mindivally, he mean, all.\n",
            "\"justoficed being hi\n",
            "hease have. to\n",
            "unvalfe to!ception. of \n",
            "epoch 2\n",
            "Epoch 1/1\n",
            "200278/200278 [==============================] - 42s 209us/step - loss: 1.6195\n",
            "--- Generating with seed: \"ligible enough; what is more difficult\n",
            "to understand is that\"\n",
            "------ temperature: 0.2\n",
            "ligible enough; what is more difficult\n",
            "to understand is that the sacrificed and simpless of the soul the same and some his expecies of the same and and the same and the sacrifice of the sacrism and the sacripal and the sacrifice of the sense of the same and the stright the condition the are the sould the best the are the sacrificed the condition and in the condition of the destroy of the souls of the same and sacrificed and the same and some the soul of th\n",
            "------ temperature: 0.5\n",
            "the same and sacrificed and the same and some the soul of the expecies of the soul shard, and the have more security should be the professions and in the\n",
            "from the sach and a cromity and relations and in the still respocuty\n",
            "of meds of the saprity of the\n",
            "relations and the strong and provers they all the really relations of the emotions in the spirit, when it is the condess and the provers, as a state conscience and the same and supposing more as it has his c\n",
            "------ temperature: 1.0\n",
            "e conscience and the same and supposing more as it has his convired both new provisical man. aunt metaspes of\n",
            "this\n",
            "stroued: in\n",
            "thus\n",
            "and an irmuntion what is for it is much ssidalnts. the following of access and\n",
            "beaps\n",
            "it who the trudity sad to the\n",
            "distress. pains id\n",
            "onlyer rematited andirespect and circumect and conduct\n",
            "and very the achow, inscituspauted the lofed are does all the depthount of his, that that happens of a doy spirit act wenems\n",
            "in\n",
            "beens\n",
            "spect\n",
            "------ temperature: 1.2\n",
            " that that happens of a doy spirit act wenems\n",
            "in\n",
            "beens\n",
            "spect as gen\n",
            "knaty,\" mereptal thmpever, he maht, yes consition to fort arainy\n",
            "exagmaming still sheaves\n",
            "from\n",
            "litery this cheidverly conclupur\", prectised way, st mitfestruch\"e of a i stain to standard--oc al impurity. a s\n",
            ".b\n",
            "yididitation of this\n",
            "greates; and neble condect\n",
            "silut\".=--seclection\n",
            "prifling that it are reformingsd--humrund\n",
            "and selforarn grogic dm ssroed, and himselfs in\n",
            "apost be lawyr indecer\n",
            "epoch 3\n",
            "Epoch 1/1\n",
            "200278/200278 [==============================] - 42s 208us/step - loss: 1.5326\n",
            "--- Generating with seed: \"im the right to include willing-as-such\n",
            "within the sphere of\"\n",
            "------ temperature: 0.2\n",
            "im the right to include willing-as-such\n",
            "within the sphere of the christian of the call that the contempless of the contemplation in the characters of the sense of the same sense of the conterness of the same as the strenct of the same that the conception the strongers of the condection in the contemplation of the strencth to the strenct of the moral morality of the strangers. the some sing and contemperation of the conception the southess and stinction of \n",
            "------ temperature: 0.5\n",
            "temperation of the conception the southess and stinction of higher will really taste of the will that the sapposing that he is s"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}