{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZhlzCJiZZcwhYGaWMYeAmVnG/j9X9jq2BqwyjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34ff94e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ', 'd', 'z', 'R', 'A', 'Q', 'a', 'G', 'p', 'M', 'D', 'v', 'K', 'c', 'e', 'x', 'N', 'H', 'b', 'V', 'u', 'g', 'r', 'L', 's', \"'\", 'n', 't', 'j', 'k', 'l', 'm', 'Z', 'U', 'O', 'S', 'F', 'i', 'h', 'q', 'f', 'w', 'B', 'o', 'E', 'X', 'T', '-', 'C', 'Y', 'y', 'J', 'W', 'P', 'I'}\n",
      "n_tokens: 55\n"
     ]
    }
   ],
   "source": [
    "tokens = set(''.join(names[:]))### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "print(tokens)\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {tokens[i]:i for i in range(n_tokens)}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[ 0  4 18  6 21  6 14 30  0]\n",
      " [ 0  7 30 43 22 50  0  0  0]\n",
      " [ 0 53 22 37 24 24 37 14  0]\n",
      " [ 0  7 37 43 11  6 26 26 14]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(units=rnn_num_units,activation='relu')### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(units=n_tokens,activation='softmax')### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.objectives import categorical_crossentropy\n",
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34dee97550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yulma          \n",
      " Rotbas         \n",
      " Coddane        \n",
      " Heriy          \n",
      " Rarefik        \n",
      "  Dod           \n",
      " Btonnegs       \n",
      " Frathe         \n",
      " Karanval       \n",
      " Ilddra         \n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpie        \n",
      " Trumpa         \n",
      " Trumpennna     \n",
      " Trumpinrel     \n",
      " Trumpo         \n",
      " Trumpand       \n",
      " Trumptryroda   \n",
      " Trumpad        \n",
      " Trumpy         \n",
      " Trumpa         \n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diaa.elsayedziada@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = 'ZV5mqXGWa7C8ISXt' #\"### YOUR TOKEN HERE ###\"\n",
    "COURSERA_EMAIL = 'diaa.elsayedziada@gmail.com' #\"### YOUR EMAIL HERE ###\"\n",
    "print(COURSERA_EMAIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 55)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "e1d93478796140b590781184cbc071ce": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
